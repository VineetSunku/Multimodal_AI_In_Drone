{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 15:35:06.305040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 15:35:07.587613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-25 15:35:07.587937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-25 15:35:07.587949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Command</th>\n",
       "      <th>Camera</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Follow the person in front of you.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detect any obstacles and avoid them.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scan the area for moving objects.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify the red car below and hover above it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Track the object moving to the right.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Command  Camera\n",
       "0              Follow the person in front of you.       1\n",
       "1            Detect any obstacles and avoid them.       1\n",
       "2               Scan the area for moving objects.       1\n",
       "3  Identify the red car below and hover above it.       1\n",
       "4           Track the object moving to the right.       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/Dataset_unsupervised.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Command</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camera</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>824</td>\n",
       "      <td>588</td>\n",
       "      <td>Return to base and perform a system check</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420</td>\n",
       "      <td>972</td>\n",
       "      <td>Capture image of the landing site after landing</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Command                                                             \n",
       "         count unique                                              top freq\n",
       "Camera                                                                     \n",
       "0          824    588        Return to base and perform a system check   13\n",
       "1         1420    972  Capture image of the landing site after landing   11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Camera').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(824, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nocam = df[df['Camera']==0]\n",
    "df_nocam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cam = df[df['Camera']==1]\n",
    "df_cam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(824, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cam_downsampled = df_cam.sample(df_nocam.shape[0])\n",
    "df_cam_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_cam_downsampled, df_nocam])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Command</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camera</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>824</td>\n",
       "      <td>588</td>\n",
       "      <td>Return to base and perform a system check</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>824</td>\n",
       "      <td>640</td>\n",
       "      <td>Fly over the area and assess the situation.</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Command                                                         \n",
       "         count unique                                          top freq\n",
       "Camera                                                                 \n",
       "0          824    588    Return to base and perform a system check   13\n",
       "1          824    640  Fly over the area and assess the situation.   11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_balanced\n",
    "df.groupby('Camera').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Command'],df['Camera'], stratify=df['Camera'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1804                         Adjust the camera zoom to 5x\n",
       "1839                 Hover at 10 meters and inspect cargo\n",
       "1782    Obtain a high-resolution image of the surround...\n",
       "1519    Fly to the designated location and begin data ...\n",
       "Name: Command, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "X_train.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:38:40.470803: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Type 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Type 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[4][0]',            \n",
      "                                768),                             'keras_layer[4][1]',            \n",
      "                                 'sequence_output':               'keras_layer[4][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " the_college_dropout (Dropout)  (None, 768)          0           ['keras_layer_1[4][13]']         \n",
      "                                                                                                  \n",
      " hidden_layer_1 (Dense)         (None, 128)          98432       ['the_college_dropout[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['hidden_layer_1[0][0]']         \n",
      "                                                                                                  \n",
      " hidden_layer_2 (Dense)         (None, 64)           8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['hidden_layer_2[0][0]']         \n",
      "                                                                                                  \n",
      " hidden_layer_3 (Dense)         (None, 32)           2080        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            33          ['hidden_layer_3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,591,042\n",
      "Trainable params: 108,801\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# BERT layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"the_college_dropout\")(outputs['pooled_output'])\n",
    "\n",
    "# Adding multiple hidden layers\n",
    "l = tf.keras.layers.Dense(128, activation='relu', name=\"hidden_layer_1\")(l)\n",
    "l = tf.keras.layers.Dropout(0.2)(l)\n",
    "l = tf.keras.layers.Dense(64, activation='relu', name=\"hidden_layer_2\")(l)\n",
    "l = tf.keras.layers.Dropout(0.2)(l)\n",
    "l = tf.keras.layers.Dense(32, activation='relu', name=\"hidden_layer_3\")(l)\n",
    "\n",
    "# Output layer\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_2 (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_3 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer_2[0][0]',          \n",
      "                                None, 768),                       'keras_layer_2[0][1]',          \n",
      "                                 'default': (None,                'keras_layer_2[0][2]']          \n",
      "                                768),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_3[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6959 - accuracy: 0.5536 - precision: 0.5502 - recall: 0.5843\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6571 - accuracy: 0.6069 - precision: 0.6129 - recall: 0.5789\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 140s 3s/step - loss: 0.6337 - accuracy: 0.6170 - precision: 0.6110 - recall: 0.6424\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 139s 3s/step - loss: 0.6316 - accuracy: 0.6365 - precision: 0.6369 - recall: 0.6343\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 137s 3s/step - loss: 0.6136 - accuracy: 0.6655 - precision: 0.6658 - recall: 0.6640\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 131s 3s/step - loss: 0.6010 - accuracy: 0.6784 - precision: 0.6714 - recall: 0.6977\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.5933 - accuracy: 0.6966 - precision: 0.6964 - recall: 0.6964\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5828 - accuracy: 0.7080 - precision: 0.7026 - recall: 0.7206\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5721 - accuracy: 0.6972 - precision: 0.7000 - recall: 0.6896\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.5594 - accuracy: 0.7269 - precision: 0.7289 - recall: 0.7220\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.5512 - accuracy: 0.7276 - precision: 0.7274 - recall: 0.7274\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.5351 - accuracy: 0.7572 - precision: 0.7599 - recall: 0.7517\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5427 - accuracy: 0.7357 - precision: 0.7361 - recall: 0.7341\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5271 - accuracy: 0.7586 - precision: 0.7550 - recall: 0.7652\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5196 - accuracy: 0.7647 - precision: 0.7606 - recall: 0.7719\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 133s 3s/step - loss: 0.5158 - accuracy: 0.7741 - precision: 0.7714 - recall: 0.7787\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.5083 - accuracy: 0.7707 - precision: 0.7663 - recall: 0.7787\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 134s 3s/step - loss: 0.4960 - accuracy: 0.7795 - precision: 0.7738 - recall: 0.7895\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 132s 3s/step - loss: 0.4995 - accuracy: 0.7687 - precision: 0.7646 - recall: 0.7760\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 132s 3s/step - loss: 0.4942 - accuracy: 0.7802 - precision: 0.7793 - recall: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e0de80160>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 16s 2s/step - loss: 0.4917 - accuracy: 0.7939 - precision: 0.8769 - recall: 0.6867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49171197414398193,\n",
       " 0.7939394116401672,\n",
       " 0.8769230842590332,\n",
       " 0.6867470145225525]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.318452  ],\n",
       "       [0.34977323]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"move the drone 10 m\", \"move towards the edible object\"]\n",
    "prediction = model.predict(test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 16s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74,  8],\n",
       "       [26, 57]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'Truth')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81        82\n",
      "           1       0.88      0.69      0.77        83\n",
      "\n",
      "    accuracy                           0.79       165\n",
      "   macro avg       0.81      0.79      0.79       165\n",
      "weighted avg       0.81      0.79      0.79       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
